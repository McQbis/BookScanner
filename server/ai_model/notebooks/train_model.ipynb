{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a neural network model to generate a document deformation mesh in an image.\n",
    "\n",
    "Author: Maciej Kubiś\n",
    "\n",
    "Date: 2025-03-24\n",
    "\n",
    "The notebook will allow training of various AI models created using **PyTorch**. Various architectures modeled on **U-Net** will be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\") \n",
    "\n",
    "from data_generator import DocumentImageGenerator\n",
    "from neuralnet_handler import NeuralNetHandler\n",
    "from unet_optimized import UNetFlexible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "It is possible to set device where will be handle neural network. Image generator require file with any text to produce random content of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "generator = DocumentImageGenerator(\"../src/assets/text.txt\")\n",
    "\n",
    "nn_handler = NeuralNetHandler(None, generator, device, 3000, 0.01, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.set_seed(42)\n",
    "import cv2\n",
    "generator.regenerate_data()\n",
    "i = 1\n",
    "for img in generator.get_images():\n",
    "    cv2.imwrite(f\"../src/assets/generated_image_example_{i}.jpg\", img*255)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net model\n",
    "\n",
    "\n",
    "The `UNetFlexible` is a custom implementation of the U-Net architecture designed for grid regression (e.g., predicting (x, y) offsets per pixel). It is built to work with **arbitrary input image sizes**, not just those that are powers of 2.\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "- **Encoder**: 3 convolutional blocks with downsampling (`MaxPool2d`), each doubling the number of channels.\n",
    "- **Bottleneck**: A deeper feature extractor that expands feature capacity.\n",
    "- **Decoder**: 3 upsampling blocks using `bilinear interpolation`, followed by `Conv2d` layers and skip connections.\n",
    "- **Final Output**: A `1x1 Conv2d` layer projecting to 2 channels (for `(x, y)` offset prediction per pixel).\n",
    "\n",
    "### Skip Connections\n",
    "\n",
    "The model uses **skip connections** with dynamic interpolation (`F.interpolate`) to **align spatial dimensions** when concatenating encoder and decoder feature maps — this ensures compatibility with **any image size**, including those **not divisible by powers of 2**.\n",
    "\n",
    "### Output Behavior\n",
    "\n",
    "- Input shape: `(N, 1, H, W)` — single-channel grayscale images.\n",
    "- Output shape: `(N, 2, H, W)` — two-channel output with predicted `(x, y)` offsets for each pixel.\n",
    "\n",
    "### Customization\n",
    "\n",
    "- `base_channels`: Controls the number of filters in the first encoder block (default = 64).\n",
    "- Fully convolutional — supports dynamic image sizes at inference without needing resizing to specific dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetFlexible(base_channels=64)  # You can adjust base_channels as needed\n",
    "nn_handler.set_model(model, \"unet_deform\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for plotting results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot():\n",
    "    # Clear the output before plotting\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Plot training progress\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(nn_handler.get_train_losses(), label='Training Loss', color='blue')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss (U-Net)')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.xlim(left=0)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot validation progress\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(nn_handler.get_val_losses(), label='Validation Loss', color='green')\n",
    "    plt.xlabel('Evaluation Steps (every 60 epochs)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Validation Loss (U-Net)')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.xlim(left=0)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_handler.train(resume_from_checkpoint=True)\n",
    "\n",
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensure model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_handler.save_model(\"../models/unet_deform.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
